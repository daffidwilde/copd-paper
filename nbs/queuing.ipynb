{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling a COPD ward\n",
    "\n",
    "The simplest model using the data available to us is an $M|M|c$ queuing model. In this model, the following assumptions are made:\n",
    "\n",
    "1. Interarrival and service times of patients are each exponential with some mean.\n",
    "2. There are $c$ servers available to arriving patients at a single node representing the overall resource availability at the hospital.\n",
    "3. There is no queue capacity.\n",
    "4. A first-in first-out service policy is implemented.\n",
    "\n",
    "### Choosing the distributions\n",
    "\n",
    "#### Arrivals\n",
    "\n",
    "Each group of patients has its own arrival distribution. The parameter of this distribution is taken to be the reciprocal of the mean interarrival times for that group.\n",
    "\n",
    "#### Services (derived from responses)\n",
    "\n",
    "Like arrivals, each group of patients has its own service time distribution. This will be calculated approximately via the length of a patient's stay. Technically, length of stay is the total time spent in the system, i.e. the response time. Without full details of process order and idle periods during a spell, we will consider the mean service time, $\\frac{1}{\\mu}$, to be proportional to the mean total system time, $\\frac{1}{\\phi}$, such that:\n",
    "\n",
    "$$ \\mu = p \\phi $$\n",
    "\n",
    "where $p \\in (0, 1]$ is some parameter to be determined for each group.\n",
    "\n",
    "### Determining parameters\n",
    "\n",
    "As the full details of how the patients move through the hospital system, and the details of the system itself, are unknown, an appropriate number of servers $c$ must be found as well as $p$.\n",
    "\n",
    "In order to estimate \"good\" values of each $p$ and the value of $c$, the system will be simulated using a number of parameter sets. Then the total time distribution will be compared with that in the available data via the (first) Wasserstein distance. This distance measures the approximate \"work\" required to move between two probability distributions where work is loosely defined as the product of the amount of the distribution required to be moved and the distance it must be moved.\n",
    "\n",
    "More formally, the Wasserstein distance between two probability distributions $f$ and $g$ is defined as:\n",
    "\n",
    "$$ W(f, g) = \\int_{-\\infty}^{\\infty} \\left\\vert F - G \\right\\vert $$\n",
    "\n",
    "where $F$ and $G$ are the CDFs of $f$ and $g$ respectively.\n",
    "\n",
    "Then the parameter set with the smallest distance is taken to be the most appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "from collections import defaultdict\n",
    "\n",
    "import ciw\n",
    "from ciw.dists import Exponential\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import special, stats\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn-colorblind\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "copd = pd.read_csv(\n",
    "    \"../data/copd_clustered.csv\", parse_dates=[\"admission_date\", \"discharge_date\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code gets the number of patients in the hospital system on a given date.\n",
    "\n",
    "```python\n",
    "def get_n_patients(data, date):\n",
    "\n",
    "    patients_in_system_at_date = (\n",
    "        (data[\"admission_date\"] <= date)\n",
    "        & (date <= data[\"discharge_date\"])\n",
    "    )\n",
    "\n",
    "    return len(data[patients_in_system_at_date])\n",
    "\n",
    "\n",
    "get_parts = lambda x: (x.year, x.month, x.day)\n",
    "\n",
    "year, month, day = get_parts(copd[\"admission_date\"].min())\n",
    "start_date = pd.to_datetime(f\"{year}-{month}-{day}\")\n",
    "\n",
    "year, month, day = get_parts(copd[\"discharge_date\"].max())\n",
    "end_date = pd.to_datetime(f\"{year}-{month}-{day + 1}\")\n",
    "\n",
    "system_size = pd.DataFrame(\n",
    "    {\"date\": pd.date_range(start=start_date, end=end_date, freq=\"d\")}\n",
    ")\n",
    "\n",
    "for intervention, data in copd.groupby(\"intervention\"):\n",
    "    system_size[intervention] = system_size[\"date\"].apply(lambda date: get_n_patients(data, date))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_times(diff):\n",
    "\n",
    "    times = diff.dt.total_seconds().div(24 * 60 * 60, fill_value=0)\n",
    "    return times\n",
    "\n",
    "    \n",
    "def get_queue_params(data, prop, dist=stats.expon):\n",
    "    \"\"\" Get the arrival and service parameters from `data` and the given `prop`. \"\"\"\n",
    "\n",
    "    inter_arrivals = (\n",
    "        data.set_index(\"admission_date\").sort_index().index.to_series().diff()\n",
    "    )\n",
    "    interarrival_times = get_times(inter_arrivals)\n",
    "    lambda_ = np.mean(interarrival_times)\n",
    "\n",
    "    mean_system_time = np.mean(data[\"true_los\"])\n",
    "    mu_estimate = mean_system_time * prop\n",
    "\n",
    "    queue_params = {\"arrival\": 1 / lambda_, \"service\": 1 / mu_estimate}\n",
    "\n",
    "    return queue_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def run_multiple_class_trial(data, column, props, num_servers, seed):\n",
    "\n",
    "    ciw.seed(seed)\n",
    "    all_queue_params = defaultdict(dict)\n",
    "    for (label, subdata), service_prop in zip(\n",
    "        data.groupby(column), props\n",
    "    ):\n",
    "        all_queue_params[label] = get_queue_params(subdata, service_prop)\n",
    "\n",
    "    N = ciw.create_network(\n",
    "        arrival_distributions={\n",
    "            f\"Class {label}\": [Exponential(params[\"arrival\"])]\n",
    "            for label, params in all_queue_params.items()\n",
    "        },\n",
    "        service_distributions={\n",
    "            f\"Class {label}\": [Exponential(params[\"service\"])]\n",
    "            for label, params in all_queue_params.items()\n",
    "        },\n",
    "        number_of_servers=[num_servers],\n",
    "    )\n",
    "\n",
    "    Q = ciw.Simulation(N)\n",
    "    Q.simulate_until_max_time(365 * 30)\n",
    "\n",
    "    records = Q.get_all_records()\n",
    "    results = pd.DataFrame(\n",
    "        [r for r in records if r.arrival_date > 365 * 10 and r.arrival_date < 365 * 20]\n",
    "    )\n",
    "\n",
    "    results[\"total_time\"] = results[\"exit_date\"] - results[\"arrival_date\"]\n",
    "    results[\"service_prop\"] = results[\"customer_class\"].apply(lambda x: props[x])\n",
    "    results[\"num_servers\"] = num_servers\n",
    "    results[\"seed\"] = seed\n",
    "\n",
    "    name = \"_\".join([str(p) for p in props]) + \"_\" + \"_\".join([str(num_servers), str(seed)])\n",
    "    results.to_csv(f\"../data/queuing/{name}.csv\", index=False)\n",
    "\n",
    "    distance = stats.wasserstein_distance(results[\"total_time\"], copd[\"true_los\"])\n",
    "    return (*props, num_servers, seed, distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##########                              ] | 26% Completed | 23min 51.4s"
     ]
    }
   ],
   "source": [
    "n_clusters = copd[\"cluster\"].nunique()\n",
    "prop_lims, steps = (0.5, 1), 6\n",
    "server_lims = (40, 56, 5)\n",
    "seeds = 1\n",
    "\n",
    "tasks = (\n",
    "    run_multiple_class_trial(\n",
    "        copd, \"cluster\", props, num_servers, seed\n",
    "    )\n",
    "    for props, num_servers, seed in it.product(\n",
    "        it.product(np.linspace(*prop_lims, steps), repeat=n_clusters),\n",
    "        range(*server_lims),\n",
    "        range(seeds),\n",
    "    )\n",
    ")\n",
    "\n",
    "with ProgressBar():\n",
    "    results = dask.compute(*tasks, scheduler=\"processes\", num_workers=8)\n",
    "\n",
    "columns = [*(f\"p_{i}\" for i in range(n_clusters)), \"num_servers\", \"seed\", \"distance\"]\n",
    "df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = df[\"distance\"].argmin()\n",
    "\n",
    "ps, c, seed, dist = df.iloc[best, :]\n",
    "ps, c, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=200)\n",
    "\n",
    "name = \"_\".join([str(p) for p in ps]) + \"_\" + \"_\".join([str(c), str(seed)])\n",
    "best_df = pd.read_csv(f\"../data/queuing/{name}.csv\")\n",
    "\n",
    "ax.hist(\n",
    "    copd[\"true_los\"],\n",
    "    bins=50,\n",
    "    alpha=0.5,\n",
    "    density=True,\n",
    "    label=\"observed data\",\n",
    ")\n",
    "ax.hist(best_df[\"total_time\"], bins=50, alpha=0.5, density=True, label=\"simulated data\")\n",
    "\n",
    "ax.set_xlim(-5, 65)\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
