% interactapasample.tex
% v1.05 - August 2017

\documentclass[]{interact}

\usepackage[caption=false]{subfig}% Support for small, `sub' figures and tables
\usepackage[nolists,tablesfirst]{endfloat}% To `separate' figures and tables from text if required
% \usepackage[doublespacing]{setspace}% To produce a `double spaced' document if required
% \setlength\parindent{24pt}% To increase paragraph indentation when line spacing is doubled

\usepackage[ruled,linesnumbered]{algorithm2e}
\newcommand{\balg}[1][htbp]{\begin{algorithm}[#1]\DontPrintSemicolon}
\newcommand{\ealg}{\end{algorithm}}

\usepackage{interval}
\intervalconfig{soft open fences}

\usepackage{pgf}
\pgfdeclarelayer{background}
\pgfsetlayers{background,main}

\usepackage{standalone}
\usepackage{subfig}
\usepackage{tikz}
\usetikzlibrary{%
    arrows,
    arrows.meta,
    backgrounds,
    decorations.pathreplacing,
    decorations.text,
    patterns,
    positioning,
    shapes.arrows,
    shapes.geometric
}


\tikzstyle{every picture} += [remember picture]
\tikzstyle{na} = [baseline=-.5ex]

\tikzset{%
    queue/.pic={%
        code{%
            \node (rect) at (38.5mm, 10mm) {};
            \draw[thick] (0, 0) -- ++(40mm, 0) -- ++(0, 20mm) -- ++(-40mm, 0);
            \foreach \val in {0, ..., #1}{%
                \draw[thick] ([xshift=-\val*5mm] 40mm, 20mm) -- ++(0, -20mm);
            };

            \foreach \val/\lab/\size in {%
                0/1/\scriptsize,
                1/2/\scriptsize,
                3/c-1/\tiny,
                4/c/\scriptsize%
            }{%
                \node[draw, circle, thick, minimum size=9.5mm] (\lab)
                    at (55mm, 29mm - \val * 9.5mm) {\size$\lab$};
                \draw[-latex, thick] (rect.east) -- (\lab.west);
            };

            \node at (55mm, 11mm) {$\vdots$};
            \node at (5mm, 10mm) {$\cdots$};
        };
    },
    myarrow/.style={%
        line width=2mm,
        draw=gray!50,
        -triangle 60,
        postaction={draw=gray!50, line width=4mm, shorten >=6mm, -},
    },
    double -latex/.style args={#1 colored by #2 and #3}{%
        -latex,
        line width=#1,
        #2,
        postaction={%
            draw,
            -latex,
            #3,
            line width=(#1)/3,
            shorten <=(#1)/4,
            shorten >=4.5*(#1)/3
        },
    },
    mypointer/.style={%
        double -latex=1mm colored by gray!50 and gray!50,
    }
}

\newlength{\imgwidth}
\setlength{\imgwidth}{.95\textwidth}
\newlength{\tabwidth}
\setlength{\tabwidth}{.9\textwidth}

\usepackage[natbibapa,nodoi]{apacite}
\setlength\bibhang{12pt}
\renewcommand\bibliographytypesize{\fontsize{10}{12}\selectfont}

\theoremstyle{plain}% Theorem-like structures provided by amsthm.sty
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\theoremstyle{remark}
\newtheorem{remark}{Remark}
\newtheorem{notation}{Notation}

\newcommand{\ctmuhb}{Cwm Taf Morgannwg University Health Board}

\definecolor{blue}{HTML}{0072B2}
\definecolor{green}{HTML}{009E73}
\definecolor{orange}{HTML}{D55E00}
\definecolor{pink}{HTML}{CC79A7}

\DeclareMathOperator*{\argmin}{arg\,min}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

% \articletype{ARTICLE TEMPLATE}% Specify the article type or omit as appropriate

\title{%
  Segmentation analysis and the recovery of queuing parameters via the
  Wasserstein distance: a study of administrative data for patients with chronic
  obstructive pulmonary disease
}

\author{%
  \name{%
    Henry Wilde\textsuperscript{a}%
    \thanks{CONTACT Henry Wilde. Email: henrydavidwilde@gmail.com},
    Vincent Knight\textsuperscript{a},
    Jonathan Gillard\textsuperscript{a}
    and Kendal Smith\textsuperscript{b}
  }
  \affil{%
    \textsuperscript{a}School of Mathematics, Cardiff University, UK;
    \textsuperscript{b}Cwm Taf Morgannwg University Health Board, UK
  }
}

\maketitle

\begin{abstract}
    This work uses a data-driven approach to analyse how the requirements of
    patients with chronic obstructive pulmonary disease (COPD) may change,
    quantifying their impact on the hospital system with which they interact.
    This approach is composed of a novel combination of often distinct modes of
    analysis: segmentation, queuing theory, and parameter recovery. Through this
    combination of methods, this work demonstrates how to overcome potential
    limitations presented by a lack of fine-grained data.

    The authors identify a clustering of the population from an administrative
    data that feeds into a multi-class \(M/G/c\) model, whose parameters are
    recovered from the data via the Wasserstein distance. This model then
    informs an analysis of the underlying system and the needs of the population
    under study.
    
    The analyses used herein consider, in effect, all types of patient arrivals
    and how they impact the system. With that, this study finds that there are
    no quick solutions to reduce the impact of COPD patients on the system,
    including adding capacity to the system. In this analysis, the only
    effective intervention to reduce the strain caused by those presenting with
    COPD is to enact external policies which directly improve the overall health
    of the COPD population before their arrival.
\end{abstract}

\begin{keywords}
OR in health services; machine learning; queuing
\end{keywords}


\section{Introduction}\label{sec:intro}

Population health research is increasingly based on data-driven methods for
patient-centred care---as opposed to those designed solely by clinical
experts. This movement is borne from the advent of accessible software and an
abundance of data. However, many such methods rely on detailed data about both
the healthcare system and its population, which may limit research where
sophisticated data pipelines are not yet in place.

This manuscript presents a method of overcoming this, using routinely gathered,
administrative hospital data to build a clustering which feeds into a
multi-class queuing model, allowing for better understanding of the healthcare
population and the system with which they interact. This work utilises a dataset
of patients presenting chronic obstructive pulmonary disease (COPD), and
demonstrates how insights can be identified by extracting information from
administrative data. COPD is a condition of particular interest to population
health research as it is known to often present as a comorbidity in
patients~\citep{Houben2019}, increasing the complexity of treatments among those
with the condition.

This work draws upon several overlapping sources within mathematical research,
and this work contributes to the literature in three ways: to theoretical
queuing research by the estimation of missing queuing parameters with the
Wasserstein distance; to operational healthcare research through the weaving
together of the combination of methods used in this work despite data
constraints; and to public health research by adding to the growing body of
mathematical and operational work around a condition that is vital to understand
operationally, socially and medically.

The remainder of this manuscript is structured as follows:

\begin{itemize}
    \item Section~\ref{sec:intro} introduces the paper and provides a literature
        review, followed by an overview of the case study dataset and its
        clustering;
    \item Section~\ref{sec:model} describes the queuing model and the estimation
        of its parameters;
    \item Section~\ref{sec:scenarios} presents several what-if scenarios with
        insight provided by the model parameterisation and the clustering;
    \item Section~\ref{sec:summary} summarises the manuscript and its findings.
\end{itemize}


\subsection{Literature review}\label{subsec:review}

Given the subject matter of this work, the relevant literature spans much of
operational research in healthcare, and the focus of this review is on the
critical topics of segmentation analysis, queuing models applied to hospital
systems, and the handling of missing or incomplete data for such queues.

\subsubsection{Segmentation analysis}

Segmentation analysis allows for the targeted analysis of otherwise
heterogeneous datasets and encompasses several techniques from operational
research, statistics and machine learning. One of the most desirable qualities
of this kind of analysis is the ability to glean and communicate simplified
summaries of patient needs to stakeholders in text or infographics; for
instance, in:~\citep{Vuik2016a,Vuik2016b,Yan2019,Yoon2020}.

The review identified three groups of patient characteristics used to segment a
patient population: system utilisation metrics; clinical attributes; and the
pathway. The last is not used to segment the patients directly, but groups their
movements through the system, typically via process
mining.~\cite{Arnolds2018}~and~\cite{Delias2015} demonstrate how this technique
can be used to improve the efficiency of a hospital system as opposed to
tackling the more relevant issue of patient-centred care. The remaining
characteristics can be segmented in a variety of ways, but recent works tend to
favour unsupervised methods---typically latent class analysis (LCA) or
clustering~\citep{Yan2018}.

LCA is a statistical, model-based method used to identify groups (latent
classes) in data by relating observations to some unobserved, categorical
attribute. The discovered relations allow the observations to be separated into
classes according to their maximum likelihood class
membership~\citep{Hagenaars2002,Lazarsfeld1968}. This method has proved useful
in the study of comorbidity patterns, as
in~\cite{Kuwornu2014}~or~\cite{Larsen2017}, where combinations of demographic
and clinical attributes are related to various subgroups of chronic diseases.

Similarly to LCA, clustering identifies groups (clusters) in data to produce
labels for its instances. Clustering methods are varied, but the common theme is
to maximise homogeneity within, and heterogeneity between, each
cluster~\citep{Everitt2011}. Of these methods, the \(k\)-means paradigm is the
most popular form in healthcare modelling literature. Some recent examples
include:~\cite{%
    Elbattah2017,Haraty2015,Ogbuabor2018,Santhi2010,Silitonga2018,Vuik2016a%
}. The \(k\)-means method iteratively partitions numerical data into
\(k \in \mathbb N\) distinct parts where \(k\) is fixed a priori, according to a
heterogeneity function. This method's popularity is likely due to its
simplicity, scalability, and that its implementations are
concise~\citep{Olafsson2008,Wu2009}.

In addition to \(k\)-means, hierarchical clustering methods have proven useful
in healthcare applications. In~\cite{Vuik2016a}, hierarchical clustering is used
to identify a suitable number of patient clusters. Likewise, hierarchical
clustering has been used to profile broader healthcare metrics such as patient
utilisation patterns~\citep{Zayas2016} or mapping out effective leadership
models~\cite{Hargett2017}. Also, supervised hierarchical segmentation methods
such as classification and regression trees have been used where an existing,
well-defined, label is of particular significance~\cite{Harper2006,Kumar2019}.

\subsubsection{Queuing models}

Since the seminal works of~\cite{Erlang1917,Erlang1920} established the
core concepts of queuing theory, its application to real services has become
abundant, including the healthcare service. Queuing theory is a mature
discipline with many facets that extend beyond the needs of this manuscript.
Comprehensive and informative introductions to queues and their simulation may
be found in~\citep{Bhat2015,Shortle2018,Stewart2009}.

Applying these models to healthcare settings can reveal many aspects of the
underlying system. A common area of study in healthcare settings is of
service capacity.~\cite{McClain1976} is an early example of such work where
acute bed capacity was determined using hospital occupancy data. More
modern works~\cite{Bittencourt2018,Palvannan2012,Pinto2014} consider more
detailed datasets to build their models. Moreover, model outputs are catered
towards being actionable---as is the prerogative of operational research. For
instance,~\cite{Pinto2014} devises categorisations for hospital beds and
arrivals. A further example is~\cite{Komashie2015}, where queuing models are
used to measure and understand satisfaction among patients and staff.

In addition to theoretic models, queuing research has expanded
to include computer simulation models. Simulating queues (or networks thereof)
captures the stochastic nuances of hospital systems better than their theoretic
counterparts. Example areas include the construction and simulation of Markov
processes via process mining~\citep{Arnolds2018,Rebuge2012}, multi-class queuing
networks~\citep{Cochran2009}, and patient flow~\citep{Bhattacharjee2014}.

There are numerous tools available for simulating queues, but few address core
issues like reproducibility.~\cite{Dagkakis2016} provides a review on this
subject. A common approach to building simulation models of queues is to use a
graphical user interface such as Simul8. These tools have the benefits of being
highly visual, making them attractive to organisations looking to implement
queuing models without the necessary technical expertise. However, they can
foster poor simulation practices~\cite{Bell1987}.~\cite{Brailsford2013}
discusses the issues around operational research and simulation being taken up
in the NHS despite the availability of intuitive software packages like Simul8.

Reproducibility is of great importance to scientific research but remains an
issue in simulation research generally~\citep{Fitzpatrick2019}. When considering
issues with reproducibility in scientific computing (simulation included), the
source of any concerns is often with the software used~\citep{Ivie2018}. Using
well-developed, open-source software can alleviate these issues as how they
are used involves less uncertainty and requires more rigour than `drag-and-drop'
software.

The simulation framework of choice for this manuscript is the discrete event
simulation library, Ciw~\citep{Palmer2019}. Ciw is written in Python, and is a
well-developed piece of open-source software, adhering to best practices in
research software development such as those set out in~\cite{Benureau2018}
and~\cite{Jimenez2017}. In~\cite{Palmer2019}, the authors stress how ensuring
sustainable and reproducible simulation work are at the core of their
development process.

\subsubsection{Handling incomplete queue data}

As discussed throughout this paper, the data used in this work is less detailed
than in comparative works. Without access to such data---but intending to gain
insight from what is available---it is imperative to bridge the gap left by the
incomplete data.

It is often the case that, where suitable data is not immediately available,
further inquiry in that line of research will stop. Queuing models in healthcare
settings appear to be such a case.~\cite{Asanjarani2017} is a bibliographic work
that collates articles on the estimation of queuing system
characteristics---including their parameters. Despite its breadth of almost 300
publications from 1955, the authors identify two articles as being applied
to healthcare:~\cite{Mohammadi2012,Yom2014}. Both works consider customers who
can re-enter services during their time in the system, which is mainly of value
when considering the effect of unpredictable behaviour in intensive care units,
for instance.~\cite{Mohammadi2012} seeks to approximate service and re-service
densities through a Bayesian approach and filtering out those customers seeking
to be serviced again.~\cite{Yom2014} considers an extension to the \(M/M/c\)
queue with direct re-entries. The devised model is then used to determine
resource requirements in two healthcare settings.

Aside from healthcare-specific works, the approximation of queue parameters has
formed a part of modern queuing research. However, the scope is
primarily focused on theoretic approximations rather than by
simulation.~\cite{Djabali2018}~and~\cite{Goldenshluger2016} are two such works
that attempt to estimate a general service time distribution in single server
and infinite server queues, respectively.

\subsection{Overview of the dataset and its clustering}\label{subsec:overview}

\ctmuhb\ provided the dataset used in this work. The dataset contains an
summary of 5,231 patients presenting COPD from February 2011 through March 2019,
covering 10,861 hospital spells. A patient spell is defined as the continuous
stay of a patient using a hospital bed on premises controlled by a healthcare
provider, and is made up of one or more patient episodes. An episode is defined
as any continuous period of care provided by the same consultant.
Figure~\ref{fig:spell} contains an example of the relationship between episodes
and spells.

\begin{figure}
    \centering
    \resizebox{\imgwidth}{!}{\input{spell}}
    \caption{A Gantt chart of two patient spells across three episodes}
    \label{fig:spell}
\end{figure}

The following attributes describe the spells included in the dataset studied in
this work:

\begin{itemize}
    \item Personal identifiers and information, i.e. patient and spell ID
        numbers, and identified gender;
    \item Admission/discharge dates and approximate times;
    \item Attributes summarising the clinical path of the spell including
        admission/discharge methods, and the number of episodes, consultants and
        wards in the spell;
    \item International Classification of Diseases (ICD) codes and primary
        Healthcare Resource Group (HRG) codes from each episode;
    \item Indicators for any COPD intervention. The value for any given instance
        in the dataset (i.e. a spell) is one of no intervention, pulmonary
        rehabilitation (PR), specialist nursing (SN), and both interventions;
    \item Charlson Comorbidity Index (CCI) contributions from several long term
        conditions (LTCs) as well as indicators for some other conditions such
        as sepsis and obesity. CCI is useful in anticipating hospital
        utilisation as a measure for the burdens associated with
        comorbidity~\cite{Simon2011};
    \item Rank under the 2019 Welsh Index of Multiple Deprivation (WIMD),
        indicating relative deprivation of the postcode area the patient lives
        in which is known to be linked to COPD prevalence and
        severity~\cite{Collins2018,Sexton2016,Steiner2017}.
\end{itemize}

In addition to the above, the following attributes were engineered for each
spell:

\begin{itemize}
    \item Age and spell cost data were linked to approximately half of the
        spells in the dataset from another administrative dataset;
    \item The presenting ICD codes were generalised to their categories
        according to NHS documentation and counts for each category were
        attached. This reduced the number of values from
        1,926 codes to 21 categories;
    \item A measure of admission frequency was calculated by taking the number
        of COPD-related admissions in the last twelve months linked to the
        associated patient ID number.
\end{itemize}

The attributes included in the clustering encompass utilisation metrics and
clinical attributes relating to the spell. They comprise the summary clinical
path attributes, the CCI contributions and condition indicators, the WIMD rank,
length of stay (LOS), COPD intervention, and the engineered attributes (not
including age or costs due to a lack of coverage).

With these attributes selected, a clustering algorithm must be chosen. Two
critical specifications are that it must handle mixed-type data and be
interpretable by stakeholders. The authors of~\cite{Jahangirian2015} present an
analysis of the factors resulting in a low level of engagement from stakeholders
with healthcare simulation work. The key findings indicate that complexity and
communication are the limiting factors for stakeholders, so the onus rests with
researchers to make their models informative, effective and transferable.

Given these constraints, the \(k\)-prototypes algorithm is a strong candidate.
Presented in~\cite{Huang1997a} alongside the \(k\)-modes algorithm for
categorical clustering, the \(k\)-prototypes algorithm is a mixed-type
extension to the \(k\)-modes and \(k\)-means algorithms. In effect, the
\(k\)-prototypes algorithm separates the dataset it acts on into its numeric and
categorical attributes before applying \(k\)-means and \(k\)-modes on the
respective parts. The cost functions for each of these parts are then combined
to give a single cost function according to a weight, \(\gamma \in \mathbb R\).
This weight is also used to define the dissimilarity between two points, \(X\)
and \(Y\), in a dataset:

\begin{equation}\label{eq:kprototypes}
    d(X, Y) = \sum_{j=1}^{p} \left(x_j - y_j\right)^2 + \gamma \sum_{j=p+1}^{m}
    \delta \left(x_j, y_j\right)
\end{equation}

The choice of \(\gamma\) is of particular importance as it balances the
contribution of each data type to the objective function. The seminal
work~\cite{Huang1997a} investigated the effect of various \(\gamma\) values, and
determined that a sensible, robust value for \(\gamma\) is the average of the
standard deviations for the numeric attributes. The analysis for this work found
that this value for \(\gamma\) provided a useful clustering; as such, no further
modifications were made.

To determine the optimal number of clusters, \(k\), the knee point detection
algorithm~\cite{Satopaa2011} was used with a range of potential values for \(k\)
from two to ten. This range was based on what may be considered feasibly
informative to stakeholders. This process revealed an optimal value for \(k\) of
four, but both three and five clusters were considered; both were eliminated due
to a lack of separation between the cluster characteristics.

\begin{table}
    \centering
    \resizebox{\textwidth}{!}{\input{summary}}
    \caption{%
        A summary of clinical and condition-specific characteristics for each
        cluster and the population
    }
    \label{tab:summary}
\end{table}

The dataset studied here is confidential, but a synthetic analogue illustrating
the clustering has been archived under~\texttt{DOI:10.5281/zenodo.3908167}.
Table~\ref{tab:summary} provides a summary of the dataset and its clustering.
Note that a negative length of stay indicates that the patient had passed away
prior to arriving at the hospital; these spells have been omitted from further
analysis. This table separates each cluster and the overall dataset (referred to
as the population). From this table, insights can be gained about the segments
identified by the clustering. For instance, the needs of each cluster can be
summarised succinctly:

\begin{itemize}
    \item Cluster 0 represents those spells with {\slshape low clinical
        complexity but high resource requirements}. The mean spell cost is
        almost four times the population average, and the shortest spell is
        almost two weeks long. Moreover, the median number of COPD-related
        admissions in the last year is elevated, indicating that patients
        presenting in this way require more interactions with the system.
    \item Cluster 1, the second-largest segment, represents the spells with
        {\slshape complex clinical profiles despite lower resource
        requirements}. Specifically, the spells in this cluster have the highest
        median CCI and number of LTCs, and the highest condition prevalence
        across all clusters but the second-lowest length of stay and costs.
    \item Cluster 2 represents the majority of spells and those where {\slshape
        resource requirements and clinical complexities are minimal}; these
        spells are the shortest, and the patients present with fewer diagnoses
        and a lower median CCI than any other cluster. Also, the spells in
        Cluster 2 have the highest intervention prevalence. However, they have
        the lowest condition prevalence across all clusters.
    \item Cluster 3 represents the smallest but perhaps most critical section of
        the population: spells with {\slshape high complexity and high resource
        needs}. The patients within Cluster 3 are the oldest and are some of the
        most frequently returning despite having the lowest intervention rates.
        The lengths of stay vary between seven and 32 weeks, and the mean spell
        cost is almost eight times the population average. This cluster also has
        the second-highest median CCI, and the highest median concurrent
        diagnoses.
\end{itemize}

Figures~\ref{fig:los}~through~\ref{fig:icds} show the distributions for some
of the clinical characteristics for each cluster. Each of these figures also
shows the distribution of the same attributes when splitting the population by
intervention. While this classical approach---of splitting a population based on
a condition or treatment---can provide some insight, it has been included to
highlight the value added by segmenting the population without such a
prescriptive framework.

\begin{figure}
    \centering
    \subfloat[]{%
        \resizebox*{\imgwidth}{!}{%
            \includegraphics[width=\linewidth]{cluster_true_los}
        }\label{fig:cluster_los}
    }

    \subfloat[]{%
        \resizebox*{\imgwidth}{!}{%
            \includegraphics[width=\linewidth]{intervention_true_los}
        }\label{fig:intervention_los}
    }
    \caption{%
        Histograms for length of stay by~\subref{fig:cluster_los}~cluster
        and~\subref{fig:intervention_los}~intervention
    }
    \label{fig:los}
\end{figure}

\begin{figure}
    \centering
    \subfloat[]{%
        \resizebox*{\imgwidth}{!}{%
            \includegraphics[width=\linewidth]{cluster_spell_cost}
        }\label{fig:cluster_cost}
    }

    \subfloat[]{%
        \resizebox*{\imgwidth}{!}{%
            \includegraphics[width=\linewidth]{intervention_spell_cost}
        }\label{fig:intervention_cost}
    }
    \caption{%
        Histograms for spell cost by~\subref{fig:cluster_cost}~cluster
        and~\subref{fig:intervention_cost}~intervention
    }
    \label{fig:cost}
\end{figure}

Figure~\ref{fig:los} shows the length of stay distributions as histograms.
Figure~\ref{fig:cluster_los} demonstrates the different bed resource
requirements well for each cluster in that their differences are not only a
matter of varying means and ranges, but entirely different shapes to their
distributions. All the distributions are positively skewed, but there is no real
consistency beyond that. When comparing this to
Figure~\ref{fig:intervention_los}, there is undoubtedly some variety, but the
overall shapes of the distributions are similar. The exception is the spells
with no COPD intervention, where binning could not improve the visualisation due
to the spread in their lengths of stay.

The same conclusions can be drawn from Figure~\ref{fig:cost} about costs;
there are distinct patterns between the clusters, and they align with the
patterns seen in Figure~\ref{fig:los}. Such patterns are expected given that
length of stay is a driving force of healthcare costs. Equally, there does not
appear to be any immediate difference in the distribution of costs when
splitting by intervention.

\begin{figure}
    \centering
    \subfloat[]{%
        \resizebox*{\imgwidth}{!}{%
            \includegraphics[width=\linewidth]{cluster_charlson_gross}
        }\label{fig:cluster_charlson}
    }

    \subfloat[]{%
        \resizebox*{\imgwidth}{!}{%
            \includegraphics[width=\linewidth]{intervention_charlson_gross}
        }\label{fig:intervention_charlson}
    }
    \caption{%
        Histograms for CCI by~\subref{fig:cluster_charlson}~cluster
        and~\subref{fig:intervention_charlson}~intervention
    }\label{fig:charlson}
\end{figure}

Similarly to the previous figures, Figure~\ref{fig:charlson} shows that
clustering has revealed distinct patterns in the CCI of the spells within each
cluster, whereas splitting by intervention does not. All clusters other than
Cluster 2 show clear, heavy tails, and in the cases of Clusters 1 and 3, the
body of the data exists far from the origin as indicated in
Table~\ref{tab:summary}. In contrast, the plots in
Figure~\ref{fig:intervention_charlson} all display similar, highly skewed
distributions regardless of intervention.

\begin{figure}
    \centering
    \subfloat[]{%
        \resizebox*{\imgwidth}{!}{%
            \includegraphics[width=\linewidth]{cluster_ltcs}
        }\label{fig:cluster_ltcs}
    }

    \subfloat[]{%
        \resizebox*{\imgwidth}{!}{%
            \includegraphics[width=\linewidth]{intervention_ltcs}
        }\label{fig:intervention_ltcs}
    }
    \caption{%
        Proportions of the number of concurrent LTCs in a spell
        by~\subref{fig:cluster_ltcs}~cluster
        and~\subref{fig:intervention_ltcs}~intervention
    }\label{fig:ltcs}
\end{figure}

\begin{figure}
    \centering
    \subfloat[]{%
        \resizebox*{\imgwidth}{!}{%
            \includegraphics[width=\linewidth]{cluster_icds}
        }\label{fig:cluster_icds}
    }

    \subfloat[]{%
        \resizebox*{\imgwidth}{!}{%
            \includegraphics[width=\linewidth]{intervention_icds}
        }\label{fig:intervention_icds}
    }
    \caption{%
        Proportions of the number of concurrent ICDs in a spell
        by~\subref{fig:cluster_icds}~cluster
        and~\subref{fig:intervention_icds}~intervention
    }\label{fig:icds}
\end{figure}

Figures~\ref{fig:ltcs}~and~\ref{fig:icds} show the proportions of each grouping
presenting levels of concurrent LTCs and ICDs, respectively. By exposing the
distribution of these attributes, the clinical complexity of each cluster can be
captured better than with Table~\ref{tab:summary} alone. In
Figure~\ref{fig:cluster_ltcs}, there are distinct LTC count profiles among the
clusters: Cluster 0 is typical of the population; Cluster 1 shows that no
patient presented COPD solely as an LTC in their spells, and more than half
presented at least three; Cluster 2 is similar to the population but is strongly
biased towards patients presenting only COPD; Cluster 3 has the
closest-to-uniform spread among the four bins despite the increased length of
stay and CCI, suggesting a diverse array of patients in terms of their long-term
medical needs.

Figure~\ref{fig:cluster_icds} largely mirrors these cluster profiles with the
number of concurrent ICDs. There are some points of interest, however. Firstly,
Cluster 1 has a relatively low-leaning distribution of ICDs that does not align
with the high rates of LTCs. Secondly, the vast majority of spells in Cluster
3 present with at least nine ICDs suggesting a wide range of conditions and
comorbidities beyond the LTCs used to calculate CCI.\

Conversely, little can be drawn from the same figures for the interventions
(Figures~\ref{fig:intervention_ltcs}~and~\ref{fig:intervention_icds}). One thing
of note is that patients receiving both interventions (or either, in fact) have
disproportionately fewer LTCs and concurrent ICDs when compared to the
population. Aside from this, the profiles of each intervention are similar.

As discussed earlier, the purpose of this manuscript is to construct a queuing
model for the data described here. Insights have already been gained into the
needs of the segments identified in this section. However, to glean further 
insights, some parameters of the queuing model must be recovered from the data.
The following section describes how these parameters are derived using the
dataset at hand.


\section{Constructing the queuing model}\label{sec:model}

Following on from recent literature~\citep{Steins2013,Williams2015}, this work
employs a single node queue to model a hypothetical ward of patients presenting
COPD.\ Additionally, the segmentation found in Section~\ref{subsec:overview}
provides a set of classes in the queue.

Without full details of the process order or idle periods during a spell, some
assumption must be made about the actual `service' time of a patient in the
hospital. It is assumed here that the mean service time of a group of patients
may be approximated via their mean length of stay, i.e. the mean time spent in
the system. As indicated in Figure~\ref{fig:cluster_los}, the lengths of stay
require shifting prior to fitting an exponential distribution. As such, this
work employs a \(M/G/c\) queue with shifted exponential service time
distributions for each cluster. Figure~\ref{fig:process} provides a diagrammatic
depiction of the process described in the remainder of this section to recover
and simulate this \(M/G/c\) queue.

\begin{figure}
    \centering%
    \resizebox{!}{.9\textheight}{\input{process}}
    \caption{%
        A diagrammatic depiction of the queuing parameter recovery process
    }\label{fig:process}
\end{figure}


\subsection{Deriving the model parameters}\label{subsec:derive}

Under the proposed \(M/G/c\) model, the following assumptions are made:

\begin{enumerate}
    \item Inter-arrival and service times of patients are each exponentially
        distributed with some mean and a `shift' defined in~\eqref{eq:shifted}.
        This distribution is used to simplify the model parameterisation.
    \item There are \(c \in \mathbb{N}\) servers available to arriving patients
        at the node representing the overall resource availability, including
        bed capacity and hospital staff.
    \item There is no queue or system capacity. A queue capacity of zero is used
        in~\cite{Williams2015} under the assumption that any surplus arrivals
        would be sent to another ward or unit. As this hypothetical ward
        represents the sole unit for COPD patients within the health board, this
        assumption is not held.
    \item Without the availability of expert clinical knowledge, a
        first-in-first-out service policy is employed rather than some priority
        framework.
\end{enumerate}

Each group of patients has its arrival distribution, the parameter of which is
the reciprocal of the mean inter-arrival time for that group. This parameter
is denoted \(\lambda_l\) for each cluster \(l\).

Like arrivals, each group of patients has its service time distribution. As
noted earlier in this section, the lengths of stay must be shifted before they
can be used to derive the service time distribution. Let \(T_l\) denote the set
of observed lengths of stay for cluster \(l\), and let
\(m_l = \max \left\{0, \min T_l\right\}\) be its feasible minimum. Thus, the
shifted times for cluster \(l\), denoted \(\widehat T_l\), are:

\begin{equation}\label{eq:shifted}
    \widehat T_l := \left\{t - m_l : t \in T_l\right\}
\end{equation}

An exponential distribution may be fitted to these shifted system times by
using their mean, denoted by \(\frac{1}{\phi_l}\). For the sake of simplicity,
it is assumed that for each cluster \(l\), the mean shifted service time of that
cluster, \(\frac{1}{\mu_l}\), is proportional to the corresponding mean shifted
system time such that:

\begin{equation}\label{eq:shifted_services}
    \mu_l = p_l \phi_l
\end{equation}

\noindent where \(p_l \in \interval[open left]{0}{1}\) is a service proportion
parameter to be determined for each group.

With these definitions, the service times for cluster \(l\), denoted \(S_l\),
are distributed by a shifted exponential distribution with a mean of
\(\frac{1}{\mu_l}\) and shift of \(m_l\). The probability density function of
this distribution is as follows:

\begin{equation}\label{eq:shifted_pdf}
    f(s) = \begin{cases}
        \mu_l e^{-\mu_l (s - m_l)} & \quad \text{if \(s \ge m_l\)}\\
        0 & \quad \text{otherwise}
    \end{cases}
\end{equation}

Therefore, the mean service time for spells in cluster \(l\) is given by:

\begin{equation}\label{eq:services}
    \mathbb E \left(S_l\right)
    = \int_{m_l}^{\infty} \mu_l s e^{-\mu_l (s - m_l)} \mathrm ds
    = m_l + \frac{1}{\mu_l}
\end{equation}

Since this distribution is geometrically identical to the exponential
distribution with rate \(\mu_l\) except for a shift of \(m_l\), its memoryless
property holds for \(s \ge m_l\). However, since the proposed model allows for
multiple classes and the shift terms are not the same for each cluster, the
model does not have Markovian service times and is described as a \(M/G/c\)
model.

\subsection{Validating the model}\label{subsec:validate}

One of the few ground truths available in the provided data is the observed
length of stay distribution. Given that the length of stay and resource
availability are connected, the approach here will be to simulate the length of
stay distributions for a range of values \(p_l\) and \(c\), to find the
parameters that best match the observed data.

Several methods are available for the statistical comparison of two or more
distributions, such as the Kolmogorov-Smirnov test, discrepancy approaches such
as summed mean-squared error, and \(f\)-divergences. A popular choice among the
last group (which may be considered distance-like) is the Kullback-Leibler
divergence which measures relative information entropy from one probability
distribution to another~\citep{Kullback1951}. A key issue with many of these
methods is that they lack interpretability, something which is paramount when
conveying information to stakeholders, not only for explaining how something
works, but also how its results may be explained.

As such, a reasonable candidate is the (first) Wasserstein metric, also known as
the `earth mover' distance~\citep{Vaserstein1969}. The Wasserstein metric
satisfies the definition of a mathematical metric and takes the units of the
distributions under comparison (in this case: days). These characteristics can
aid understanding and explanation. The distance measures the approximate
`minimal work' required to move between two probability distributions where
`work' can be loosely defined as the product of how much of the distribution's
mass moves and the distance by which it must be moved. Formally, the Wasserstein
distance between two probability distributions \(U\) and \(V\) is defined as:

\begin{equation}\label{eq:wasserstein}
    W(U, V) = {
        \int_{0}^{1} \left\vert F^{-1}(t) - G^{-1}(t) \right\vert \mathrm dt
    }
\end{equation}

Here, \(F\) and \(G\) are the cumulative density functions of \(U\) and \(V\),
respectively. A proof of~\eqref{eq:wasserstein} is presented
in~\cite{Ramdas2017}.

Each trial used here takes a parameter set and simulates the ward across a
series of independent repetitions. The parameter set with the smallest maximum
distance between the simulated system time distribution and the observed length
of stay distribution is taken to be the most appropriate. Specifically, let
\(T_{c,p}\) denote the system time distribution obtained from a simulation with
\(c\) servers and \(p := \left(p_0,p_1,p_2,p_3\right)\), and let \(T\) denote
the observed length of stay distribution. Then the optimal parameter set
\(\left(c^*, p^*\right)\) is given by:

\begin{equation}\label{eq:parameters}
    \left(c^*, p^*\right) = \argmin_{c, p} \left\{%
        \max \left\{ W\left(T_{c,p}, T\right) \right\}%
    \right\}
\end{equation}

The parameter sweep included values of each \(p_l\) from \(0.5\) to \(1.0\) with
a granularity of \(5.0 \times 10^{-2}\), and values of \(c\) from \(30\) to
\(50\) in steps of five. These choices were informed by the assumptions of the
model and formative analysis to reduce the parameter space given the
computational resources required to perform the simulations. Each parameter set
was repeated 50 times, with each simulation running for four years of virtual
time. The warm-up and cool-down periods were taken to be one year each, leaving
two years of simulated data from each repetition.

\begin{figure}
    \centering
    \subfloat[]{%
        \resizebox*{!}{0.28\textheight}{%
            \includegraphics[width=\linewidth]{best_params}
        }\label{fig:best_params}
    }

    \subfloat[]{%
        \resizebox*{!}{0.28\textheight}{%
            \includegraphics[width=\linewidth]{median_params}
        }\label{fig:median_params}
    }

    \subfloat[]{%
        \resizebox*{!}{0.28\textheight}{%
            \includegraphics[width=\linewidth]{worst_params}
        }\label{fig:worst_params}
    }
    \caption{%
        Histograms of the observed LOS data and the
        \subref{fig:best_params}~best-simulated,
        \subref{fig:median_params}~median-simulated, and
        \subref{fig:worst_params}~worst-simulated LOS data.
    }\label{fig:params}
\end{figure}

The results of this parameter sweep are summarised in Figure~\ref{fig:params}.
Each plot shows a comparison of the observed lengths of stay across all groups
and the newly simulated data with the best, median and worst parameter sets,
respectively. These figures highlight the importance of choosing good parameters
as the differences in the quality of the fits are stark. In the best case the
fit is uncanny, whereas the median case shows a distribution that inflates
short-stay patients despite an otherwise good fit. Meanwhile,
Figure~\ref{fig:worst_params} displays a distribution that only resembles the
observed distribution in its positive skew; the worst-case distribution lacks
the distinctive exponential nose and has a considerably heavier tail from a
disproportionate amount of long-stay patients. Table~\ref{tab:comparison}
reinforces these results numerically, showing a precise fit everywhere by the
best parameter set.

\begin{table}
    \centering
    \resizebox{\textwidth}{!}{\input{comparison}}
    \caption{%
        A comparison of the observed and simulated data based on the model
        parameters and summary statistics for length of stay
    }\label{tab:comparison}
\end{table}

In this section, the identified clustering enriched the overall queuing model
and was used to recover the parameters for several classes within that. The next
section details an investigation into the underlying system by adjusting the
parameters of the queue with the clustering.


\section{Adjusting the queuing model}\label{sec:scenarios}

This section comprises several what-if scenarios---a classic component of
healthcare operational research---under the novel parameterisation of the
queue introduced in Section~\ref{sec:model}. The outcomes of interest in this
work are server (resource) utilisation and system times. These metrics capture
the driving forces of cost and the state of the system. The objective of these
experiments is to address the following questions:
\begin{itemize}
    \item How is the system affected by a change in overall patient arrivals?
    \item How is the system affected by a change in resource availability?
    \item How is the system affected by patients moving between clusters?
\end{itemize}

Given the nature of the observed data, the model parameterisation, and
its assumptions, the effects on the chosen metrics in each scenario are in
relative terms with respect to the base case---i.e., the results from the best
parameter set recorded in Table~\ref{tab:comparison}. In particular, the data
in each scenario is scaled by the corresponding median base case value, meaning
that a metric having a value of 1 is `normal'.

As mentioned in Section~\ref{sec:intro}, the source code used throughout this
manuscript has been archived online under~\texttt{DOI:10.5281/zenodo.4457902}.
Also, the datasets generated from the simulations in this section, and the
parameter sweep from Section~\ref{sec:model}, have been archived online
under~\texttt{DOI:10.5281/zenodo.4457808}.


\subsection{Changes to overall patient arrivals}\label{subsec:arrivals}

Changes in overall patient arrivals to a queue reflect real-world scenarios
where some stimulus is improving (or worsening) the condition of the patient
population. Examples of stimuli could include an ageing population or
independent life events that lead to a change in deprivation. Within this model,
overall patient arrivals are altered using a scaling factor denoted by
\(\sigma > 0\). This scaling factor is applied to the model by multiplying each
cluster's arrival rate by \(\sigma\). That is, the new arrival rate for cluster
\(l\), denoted \(\hat\lambda_l\), is given by:

\begin{equation}\label{eq:lambda}
    \hat\lambda_{l} = \sigma\lambda_l
\end{equation}

\begin{figure}
    \centering
    \subfloat[]{%
        \resizebox*{\imgwidth}{!}{%
            \includegraphics[width=\linewidth]{lambda_time}
        }\label{fig:lambda_time}
    }

    \subfloat[]{%
        \resizebox*{\imgwidth}{!}{%
            \includegraphics[width=\linewidth]{lambda_util}
        }\label{fig:lambda_util}
    }
    \caption{%
        Plots of \(\sigma\) against relative
        \subref{fig:lambda_time}~system~time and
        \subref{fig:lambda_util}~server~utilisation
    }\label{fig:lambda}
\end{figure}

Figure~\ref{fig:lambda} shows the effect of changing patient arrivals
on the relative system metrics for values of \(\sigma\) from 0.5 to 2.0 at a
precision of \(1.0 \times 10^{-2}\). Each plot in the figure (and the subsequent
figures in this section) shows the median and interquartile range (IQR) of each
relative metric. These metrics provide an insight into the experience of a
typical user (or server) in the system. Furthermore, they reveal the stability
and variation of the body of users (or servers).

The indications of these plots align with what one might expect: as arrivals
increase, the strain on the system increases. However, it should be noted that
it also appears that the model has some amount of slack relative to the base
case. Looking at Figure~\ref{fig:lambda_time}, for instance, the relative system
time distribution stays unchanged up to \(\sigma \approx 1.2\), or an
approximate 20\% increase in arrivals of COPD patients. Beyond that, relative
system times quickly rise to an untenable point where the median time reaches
orders of magnitude above the norm.

However, Figure~\ref{fig:lambda_util} shows that the system resources reach
their worst case near to the start of that spike in relative system times (at
\(\sigma \approx 1.3\)). That is, the median server utilisation hits its maximum
at this point, and the variation in server utilisation disappears entirely. In
this scenario, the servers are constantly active. The reality of this situation
is that the system has no slack at all, and all parts of the system are under
equal load, which is not preferable given the differences in resource
requirements for the parts of a hospital system. For instance, if surgical
theatres were in constant use but administrative processing required an
equivalent amount of resources to continue running, the system would likely
falter or deteriorate entirely.


\subsection{Changes to resource availability}\label{subsec:resources}

As discussed in Section~\ref{sec:model}, the resource availability of the system
is captured by the number of parallel servers, \(c\). Therefore, to modify the
overall resource availability, only the number of servers needs to be changed.
This kind of sensitivity analysis is usually done to determine the opportunity
cost of adding service capacity to a system, e.g.\ would an increase of \(n\)
servers sufficiently increase efficiency without exceeding a budget?

To reiterate the beginning of this section: all suitable parameters are given in
relative terms, including the number of servers here. By doing this, the changes
in resource availability are more evident, and do away with any concerns as to
what a particular number of servers precisely reflects in the real world, be it
any combination of hospital beds, equipment availability and medical staff.

\begin{figure}
    \centering
    \subfloat[]{%
        \resizebox*{\imgwidth}{!}{%
            \includegraphics[width=\linewidth]{servers_time}
        }\label{fig:servers_time}
    }

    \subfloat[]{%
        \resizebox*{\imgwidth}{!}{%
            \includegraphics[width=\linewidth]{servers_util}
        }\label{fig:servers_util}
    }
    \caption{%
        Plots of the relative number of servers against relative
        \subref{fig:servers_time}~system~time and
        \subref{fig:servers_util}~server~utilisation
    }\label{fig:servers}
\end{figure}

Figure~\ref{fig:servers} shows how the relative resource availability affects
relative system times and server utilisation. In this scenario, the relative
number of servers took values from 0.5 to 2.0 at an equivalent step size of one
in the number of servers, i.e. \(c\) takes values from 17 to 70. Overall, these
figures bolster the claim from Section~\ref{subsec:arrivals} that there is some
room to manoeuvre where the system runs as normal. However, pressing on those
boundaries results in massive changes to both resource requirements and system
times.

In Figure~\ref{fig:servers_time}, this amounts to a maximum of 10\% slack in
resources before relative system times are substantially affected; further
reductions quickly result in a potentially tenfold increase in the median system
time, and up to 100 times once resource availability falls by 50\%. Moreover,
the variation in the body of the relative times (i.e. the IQR) decreases as
resource availability decreases. The reality of this is that patients arriving
at a hospital are forced to consume more resources (by merely being in a
hospital) regardless of their condition, putting added strains on the system.
Figure~\ref{fig:servers_util} mirrors these observations on the small amount of
slack in resource requirements, but (as with the previous scenario) constant
utilisation occurs quickly.

Meanwhile, it appears that there is no tangible change in relative system times
given an increase in the number of servers. This indicates that the model
carries sufficient resources to cater to the population under normal
circumstances and that adding service capacity will not necessarily improve
system times.

Again, Figure~\ref{fig:servers_util} shows that there is a substantial change in
the variation in the relative utilisation of the servers. In this case, the
variation dissipates as resource levels fall, and increases with resources.
While the relationship between real hospital resources and the number of servers
is not exact, having variation in server utilisation would suggest that small
parts of an existing system may be configured or partitioned away in the case of
some significant public health event (such as a global pandemic) without
overloading the system.


\subsection{Moving arrivals between clusters}\label{subsec:moving}

This scenario is perhaps the most relevant to actionable public health research
of those presented here. The clusters identified in this work could be
characterised by their clinical complexities and resource requirements, as done
in Section~\ref{subsec:overview}. Therefore, being able to model the movement of
some proportion of patient spells from one cluster to another will reveal how
those complexities and requirements affect the system itself. The reality is
then that if some public health policy could be implemented to initiate that
movement informed by a model such as this, then change would be seen in the real
system.

In order to model the effects of spells moving between two clusters, the
assumption is that each cluster's service time distribution stays the same (and
so does each cluster's \(p_l\)), but their arrival rates are altered according
to some transfer proportion. Consider two clusters indexed at \(l\) and \(m\),
and their respective arrival rates, \(\lambda_l\), \(\lambda_m\). Let \(\delta
\in [0, 1)\) denote the proportion of arrivals to be moved from cluster \(l\) to
cluster \(m\). Then the new arrival rates for each cluster, denoted by
\(\hat\lambda_l, \hat\lambda_m\) respectively, are:

\begin{equation}\label{eq:moving}
    \hat\lambda_l = \left(1 - \delta\right) \lambda_l
    \quad \text{and} \quad
    \hat\lambda_m = \delta\lambda_l + \lambda_m
\end{equation}

By moving patient arrivals between clusters in this way, the overall arrivals
are left the same since the sum of the arrival rates is the same. Hence, the
(relative) effect on server utilisation and system time can be measured
independently.

Figures~\ref{fig:moving_time}~and~\ref{fig:moving_util} show the effect on
relative system time and relative server utilisation, respectively, of moving
patient arrivals between clusters. In each figure, the median and IQR for the
corresponding attribute is shown, as in the previous scenarios. Each scenario
was simulated using values of \(\delta\) from 0.0 to 0.98 at steps of \(2.0
\times 10^{-2}\).

\begin{figure}
    \centering
    \includegraphics[width=\imgwidth]{moving_time}
    \caption{%
        Plots of proportions of each cluster moving to another against relative
        system time
    }\label{fig:moving_time}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\imgwidth]{moving_util}
    \caption{%
        Plots of proportions of each cluster moving to another on relative
        server utilisation
    }\label{fig:moving_util}
\end{figure}

Considering Figure~\ref{fig:moving_time}, it appears that each type of transfer
falls into one of two categories: either completely derailing the system (such
as moving any cluster to Cluster 3) or improving system times, albeit mildly. 
The latter case occurs in the following transfers:

\begin{itemize}
    \item Cluster 0 to Clusters 1 or 2
    \item Cluster 1 to Cluster 2
    \item Cluster 3 to any other cluster
\end{itemize}

A finer look at the effect of these transfer types on relative system times is
given in Table~\ref{tab:moving_time}. Likewise, their effects on relative server
utilisation is given in Table~\ref{tab:moving_util}. 

\begin{table}
    \centering%
    \resizebox{\textwidth}{!}{\input{moving_time}}
    \caption{%
        Proportional changes in median relative system time for selected cluster
        transfers
    }\label{tab:moving_time}
\end{table}

\begin{table}
    \centering%
    \resizebox{\textwidth}{!}{\input{moving_util}}
    \caption{%
        Proportional changes in median relative utilisation for selected cluster
        transfers
    }\label{tab:moving_util}
\end{table}

The message delivered by these transfers is that in order to improve system
times in hospitals, the only solution is for the patients arriving at hospital
to present with fewer resource requirements. Meanwhile, the complexity of their
condition is less influential. Achieving such reductions in resource
requirements is certainly no mean feat, but could be addressed by investing in
more advanced medical infrastructure in other parts of the healthcare system,
beyond hospitals. Furthermore, this could be achieved by implementing some
preventive policy that would help improve the overall health of the COPD
population, with particular targeting for those most-affected by the condition.

Conversely, the concern arises when either of the low resource requirement
clusters moves to Cluster 0 or Cluster 3. Even as few as one in ten of the
low-complexity, low-resource-needs arrivals in Cluster 2 moving to either
cluster results in large jumps in the median system time for all arrivals. Soon
after, as in the previous scenario, any variation in the system times
disappears, indicating an overborne system.

With relative server utilisation, the story is much the same. The ordinary
levels of high-complexity, high-resource arrivals from Cluster 3 are absorbed by
the system and moving these arrivals to another cluster bears little effect on
resource consumption levels. Likewise, either of the low-resource needs clusters
moving even slightly toward high resource requirements completely overruns the
system's resources. However, the relative utilisation levels of the system
resources can be substantially reduced by moving arrivals from Cluster 0 to
either Cluster 1 or Cluster 2, i.e. by reducing the overall resource
requirements of such spells.

In essence, this entire analysis offers two messages. Firstly, that there are
several ways in which the system can get worse and even overwhelmed. Secondly,
and more importantly, that any meaningful impact on the system must come from a
stimulus outside of the system that results in a higher proportion of healthy
patients arriving at the hospital. This conclusion is non-trivial; the first two
scenarios in this analysis show that there are no quick solutions to reduce the
effect of COPD patients on hospital capacity and length of stay. The only
effective intervention for improving the system on the whole is found through
inter-cluster transfers.


\section{Summary}\label{sec:summary}

This work presents a novel approach to investigating a healthcare population
that encompasses the topics of segmentation analysis, queuing models, and the
recovery of queuing parameters from incomplete data. This investigation is done
despite characteristic limitations in operational research concerning the
availability of fine-grained data, and the analysis in this manuscript only uses
administrative hospital spell data from patients presenting COPD from \ctmuhb.

By considering a variety of attributes present in the data, and engineering
some, a useful clustering of the spell population is identified that
successfully feeds into a multi-class \(M/G/c\) queue to model a hypothetical
COPD ward. With this model, several insights are gained by investigating
purposeful changes in the parameters of the model that have the potential to
inform actual public health policy. In particular, since neither the resource
capacity of the system nor the clinical processes of the spells are evident in
the data, service times and resource levels are not available. However, the
length of stay is. Using what is available, this work assumes that mean service
times can be parameterised using mean lengths of stay. By using the Wasserstein
distance to compare the distribution of the simulated lengths of stay data with
the observed data, a best performing parameter set is found via a parameter
sweep.

This parameterisation ultimately recovers a surrogate for service times for each
cluster, and a universal number of servers to emulate resource availability. The
parameterisation itself offers its strengths by being straightforward and
effective. Despite its simplicity, a good fit to the observed data is found,
and---as is evident from Section~\ref{sec:scenarios}---substantial and useful
insights can be gained into the needs of the population under study.

This mode of analysis, in effect, considers all types of patient arrivals and
how they each impact the system in terms of resource capacity and length of
stay. By investigating changes in both overall patient arrivals and resource
capacity, it is clear that there is no quick solution to be employed from within
the hospital to improve COPD patient spells. The only effective, non-trivial
intervention is to improve the overall health of the patients arriving at the
hospital, as is shown by moving patient arrivals between clusters. In reality,
this would correspond to an external, preventive policy that improves the
overall health of COPD patients.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{apacite}
\bibliography{bibliography}

\end{document}
